{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.506364400Z",
     "start_time": "2024-04-16T11:24:48.424169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('data.txt', mode='r', encoding='utf8') as f:\n",
    "    data = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.521225500Z",
     "start_time": "2024-04-16T11:24:52.507364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "1115394"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.549149200Z",
     "start_time": "2024-04-16T11:24:52.525213800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.559123200Z",
     "start_time": "2024-04-16T11:24:52.540173900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TOKENIZATION process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.608849300Z",
     "start_time": "2024-04-16T11:24:52.565106100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.610812700Z",
     "start_time": "2024-04-16T11:24:52.583058700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.631756500Z",
     "start_time": "2024-04-16T11:24:52.597846500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "encode_values = {}\n",
    "\n",
    "for i, char in enumerate(chars):\n",
    "    encode_values[char] = i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.632753400Z",
     "start_time": "2024-04-16T11:24:52.613804300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'\\n': 0,\n ' ': 1,\n '!': 2,\n '$': 3,\n '&': 4,\n \"'\": 5,\n ',': 6,\n '-': 7,\n '.': 8,\n '3': 9,\n ':': 10,\n ';': 11,\n '?': 12,\n 'A': 13,\n 'B': 14,\n 'C': 15,\n 'D': 16,\n 'E': 17,\n 'F': 18,\n 'G': 19,\n 'H': 20,\n 'I': 21,\n 'J': 22,\n 'K': 23,\n 'L': 24,\n 'M': 25,\n 'N': 26,\n 'O': 27,\n 'P': 28,\n 'Q': 29,\n 'R': 30,\n 'S': 31,\n 'T': 32,\n 'U': 33,\n 'V': 34,\n 'W': 35,\n 'X': 36,\n 'Y': 37,\n 'Z': 38,\n 'a': 39,\n 'b': 40,\n 'c': 41,\n 'd': 42,\n 'e': 43,\n 'f': 44,\n 'g': 45,\n 'h': 46,\n 'i': 47,\n 'j': 48,\n 'k': 49,\n 'l': 50,\n 'm': 51,\n 'n': 52,\n 'o': 53,\n 'p': 54,\n 'q': 55,\n 'r': 56,\n 's': 57,\n 't': 58,\n 'u': 59,\n 'v': 60,\n 'w': 61,\n 'x': 62,\n 'y': 63,\n 'z': 64}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.717431200Z",
     "start_time": "2024-04-16T11:24:52.627768200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "decode_values = {}\n",
    "\n",
    "for i, char in enumerate(chars):\n",
    "    decode_values[i] = char"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.718394100Z",
     "start_time": "2024-04-16T11:24:52.646718800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: '\\n',\n 1: ' ',\n 2: '!',\n 3: '$',\n 4: '&',\n 5: \"'\",\n 6: ',',\n 7: '-',\n 8: '.',\n 9: '3',\n 10: ':',\n 11: ';',\n 12: '?',\n 13: 'A',\n 14: 'B',\n 15: 'C',\n 16: 'D',\n 17: 'E',\n 18: 'F',\n 19: 'G',\n 20: 'H',\n 21: 'I',\n 22: 'J',\n 23: 'K',\n 24: 'L',\n 25: 'M',\n 26: 'N',\n 27: 'O',\n 28: 'P',\n 29: 'Q',\n 30: 'R',\n 31: 'S',\n 32: 'T',\n 33: 'U',\n 34: 'V',\n 35: 'W',\n 36: 'X',\n 37: 'Y',\n 38: 'Z',\n 39: 'a',\n 40: 'b',\n 41: 'c',\n 42: 'd',\n 43: 'e',\n 44: 'f',\n 45: 'g',\n 46: 'h',\n 47: 'i',\n 48: 'j',\n 49: 'k',\n 50: 'l',\n 51: 'm',\n 52: 'n',\n 53: 'o',\n 54: 'p',\n 55: 'q',\n 56: 'r',\n 57: 's',\n 58: 't',\n 59: 'u',\n 60: 'v',\n 61: 'w',\n 62: 'x',\n 63: 'y',\n 64: 'z'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.736344800Z",
     "start_time": "2024-04-16T11:24:52.659682500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    \"\"\"\n",
    "    Берем словарь с кодировкой и кодируем входную строку\n",
    "    :param text: входная строка\n",
    "    :return: список номеров\n",
    "    \"\"\"\n",
    "    code_num = []\n",
    "    for symbol in text:\n",
    "        code_num.append(encode_values[symbol])\n",
    "    return code_num"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.737343300Z",
     "start_time": "2024-04-16T11:24:52.674642800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def decode(numbers):\n",
    "    \"\"\"\n",
    "    Берем словарь с числами и буквами и декодируем входные числа\n",
    "    :param numbers: входные числа\n",
    "    :return: декодированные символы\n",
    "    \"\"\"\n",
    "    letters = \"\"\n",
    "    for num in numbers:\n",
    "        letters += decode_values[num]\n",
    "    return letters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.737343300Z",
     "start_time": "2024-04-16T11:24:52.691465200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[21,\n 1,\n 39,\n 51,\n 1,\n 28,\n 39,\n 60,\n 43,\n 50,\n 1,\n 15,\n 46,\n 47,\n 57,\n 58,\n 47,\n 39,\n 49,\n 53,\n 60]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"I am Pavel Chistiakov\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.739337200Z",
     "start_time": "2024-04-16T11:24:52.706425400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'I am Pavel Chistiakov'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(\"I am Pavel Chistiakov\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.752334500Z",
     "start_time": "2024-04-16T11:24:52.722382300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data_tokens = torch.tensor(encode(data), dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.927927100Z",
     "start_time": "2024-04-16T11:24:52.739337200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1115394])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tokens.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:52.952596400Z",
     "start_time": "2024-04-16T11:24:52.929919900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tokens[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.040165700Z",
     "start_time": "2024-04-16T11:24:52.954592800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Data Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% train data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.040165700Z",
     "start_time": "2024-04-16T11:24:52.999274500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_data = data_tokens[:n]\n",
    "test_data = data_tokens[n:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.041163100Z",
     "start_time": "2024-04-16T11:24:53.026233500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "train_data[:block_size+1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.045154300Z",
     "start_time": "2024-04-16T11:24:53.032188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "# ==================== ПЕРЕПИСЬ КОДА НИЖЕ ============================\n",
    "# чтобы правильно оценить лосс функцию нужно взять - логарифм 1\\на количество токенов (65)\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.120844700Z",
     "start_time": "2024-04-16T11:24:53.045154300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.121843600Z",
     "start_time": "2024-04-16T11:24:53.075966400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:53.229553400Z",
     "start_time": "2024-04-16T11:24:53.104889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:24:54.236220500Z",
     "start_time": "2024-04-16T11:24:53.215623100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5727508068084717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.203611400Z",
     "start_time": "2024-04-16T11:24:54.238214600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n",
      "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
      "I hisgothers je are!-e!\n",
      "QLYotouciullle'z,\n",
      "Thitertho s?\n",
      "NDan'spererfo cist ripl chys er orlese;\n",
      "Yo jehof h hecere ek? wferommot mowo soaf yoi\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=600)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.314443700Z",
     "start_time": "2024-04-16T11:25:15.205615Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self-Attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 2])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.360324500Z",
     "start_time": "2024-04-16T11:25:15.319430400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.372289500Z",
     "start_time": "2024-04-16T11:25:15.349350900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1808, -0.0700],\n         [-0.0894, -0.4926],\n         [ 0.1490, -0.3199],\n         [ 0.3504, -0.2238],\n         [ 0.3525,  0.0545],\n         [ 0.0688, -0.0396],\n         [ 0.0927, -0.0682],\n         [-0.0341,  0.1332]],\n\n        [[ 1.3488, -0.1396],\n         [ 0.8173,  0.4127],\n         [-0.1342,  0.4395],\n         [ 0.2711,  0.4774],\n         [ 0.2421,  0.0694],\n         [ 0.0084,  0.0020],\n         [ 0.0712, -0.1128],\n         [ 0.2527,  0.2149]],\n\n        [[-0.6631, -0.2513],\n         [ 0.1735, -0.0649],\n         [ 0.1685,  0.3348],\n         [-0.1621,  0.1765],\n         [-0.2312, -0.0436],\n         [-0.1015, -0.2855],\n         [-0.2593, -0.1630],\n         [-0.3015, -0.2293]],\n\n        [[ 1.6455, -0.8030],\n         [ 1.4985, -0.5395],\n         [ 0.4954,  0.3420],\n         [ 1.0623, -0.1802],\n         [ 1.1401, -0.4462],\n         [ 1.0870, -0.4071],\n         [ 1.0430, -0.1299],\n         [ 1.1138, -0.1641]]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.378273900Z",
     "start_time": "2024-04-16T11:25:15.364313100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 16])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.454071700Z",
     "start_time": "2024-04-16T11:25:15.384257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1808, -0.0700, -0.3596,  ..., -0.8016,  1.5236,  2.5086],\n         [-0.6631, -0.2513,  1.0101,  ...,  1.5333,  1.6097, -0.4032],\n         [-0.8345,  0.5978, -0.0514,  ..., -0.4370, -1.0012, -0.4094],\n         ...,\n         [-0.8961,  0.0662, -0.0563,  ...,  2.1382,  0.5114,  1.2191],\n         [ 0.1910, -0.3425,  1.7955,  ...,  0.3699, -0.5556, -0.3983],\n         [-0.5819, -0.2208,  0.0135,  ..., -1.9079, -0.5276,  1.0807]],\n\n        [[ 0.4562, -1.0917, -0.8207,  ...,  0.0512, -0.6576, -2.5729],\n         [ 0.0210,  1.0060, -1.2492,  ...,  0.7859, -1.1501,  1.3132],\n         [ 2.2007, -0.2195,  0.5427,  ..., -0.6445,  1.0834, -0.7995],\n         ...,\n         [ 0.3091,  1.1661, -2.1821,  ...,  0.6151,  0.6763,  0.6228],\n         [ 0.0943, -0.3156,  0.7850,  ..., -1.5735,  1.3876,  0.7251],\n         [ 0.6455, -0.3313, -1.0390,  ...,  0.0895, -0.3748, -0.4781]],\n\n        [[-0.6067,  1.8328,  0.2931,  ...,  1.0041,  0.8656,  0.1688],\n         [-0.2352, -0.2586,  0.0131,  ...,  0.6690,  0.7535, -0.5359],\n         [-1.0277,  0.5347, -0.7958,  ...,  1.0711,  0.4901, -0.4876],\n         ...,\n         [-0.6896, -0.7080, -0.3152,  ..., -2.0662, -1.1418, -0.1391],\n         [ 1.0827,  1.1522,  0.5198,  ...,  0.4970,  0.0585,  0.1033],\n         [ 0.0720,  1.1080,  0.7293,  ...,  0.3967, -0.9755,  0.5122]],\n\n        [[ 0.3330,  1.0995,  0.4034,  ...,  1.6634, -0.4718,  0.5857],\n         [-0.9579,  0.9435, -2.1992,  ..., -0.7296,  0.1653, -0.3390],\n         [ 1.5416,  1.0231,  1.3392,  ..., -0.0433, -0.2505, -0.7493],\n         ...,\n         [ 0.7450,  0.7170,  1.2668,  ...,  1.9359,  2.0350,  2.0187],\n         [ 0.0323, -0.6337,  0.2938,  ..., -0.3297, -0.0192,  0.9225],\n         [ 0.9187,  0.2998,  0.6106,  ...,  0.8282, -0.4826,  1.8330]]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:33.717593200Z",
     "start_time": "2024-04-16T11:25:33.695181100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n\n        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n\n        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n\n        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n       grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.456068200Z",
     "start_time": "2024-04-16T11:25:15.449084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.473021600Z",
     "start_time": "2024-04-16T11:25:15.457063900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:25:15.543830600Z",
     "start_time": "2024-04-16T11:25:15.469032Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
